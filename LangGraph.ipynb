{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph is a special LangChain-built library that focuses on building intelligent AI Agents using graphs. Ie, agentic state machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need these prerequisite libraries to run a graph visualization library (`pygraphviz`). We will use this library during this notebook to understand the structure of our graphs _but_ it is not required to use `langgraph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a few libraries from LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai==0.1.3 langchain==0.1.16 langchain-core==0.1.42 langgraph==0.0.37 langchainhub==0.1.15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph State\n",
    "\n",
    "We will define a custom graph state to support our agent-oriented decision making. In this we will define:\n",
    "\n",
    "* our user `input` (ie the most recent message from the user)\n",
    "* `agent_out` which is used by the graph (and our final output) to consume/output agent outputs\n",
    "* `intermediate_steps` which is a list maintained over our graph runtime to keep track of the results of previous steps\n",
    "\n",
    "During each step in our graph we will be able to add to, modify, or extract these values from our state object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union, Sequence\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    agent_out: Union[AgentAction, AgentFinish, None]\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emulate Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test a RAG-like agent we'll provide a tool that provide information as we would expect a search tool in a RAG agent to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehi_information = \"\"\"Title: EHI: End-to-end Learning of Hierarchical Index for\n",
    "Efficient Dense Retrieval\n",
    "Summary: Dense embedding-based retrieval is now the industry\n",
    "standard for semantic search and ranking problems, like obtaining relevant web\n",
    "documents for a given query. Such techniques use a two-stage process: (a)\n",
    "contrastive learning to train a dual encoder to embed both the query and\n",
    "documents and (b) approximate nearest neighbor search (ANNS) for finding similar\n",
    "documents for a given query. These two stages are disjoint; the learned\n",
    "embeddings might be ill-suited for the ANNS method and vice-versa, leading to\n",
    "suboptimal performance. In this work, we propose End-to-end Hierarchical\n",
    "Indexing -- EHI -- that jointly learns both the embeddings and the ANNS\n",
    "structure to optimize retrieval performance. EHI uses a standard dual encoder\n",
    "model for embedding queries and documents while learning an inverted file index\n",
    "(IVF) style tree structure for efficient ANNS. To ensure stable and efficient\n",
    "learning of discrete tree-based ANNS structure, EHI introduces the notion of\n",
    "dense path embedding that captures the position of a query/document in the tree.\n",
    "We demonstrate the effectiveness of EHI on several benchmarks, including\n",
    "de-facto industry standard MS MARCO (Dev set and TREC DL19) datasets. For\n",
    "example, with the same compute budget, EHI outperforms state-of-the-art (SOTA)\n",
    "in by 0.6% (MRR@10) on MS MARCO dev set and by 4.2% (nDCG@10) on TREC DL19\n",
    "benchmarks.\n",
    "Author(s): Ramnath Kumar, Anshul Mittal, Nilesh Gupta, Aditya Kusupati,\n",
    "Inderjit Dhillon, Prateek Jain\n",
    "Source: https://arxiv.org/pdf/2310.08891.pdf\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Tools\n",
    "\n",
    "We will define two tools for this agent, a `search` tool (which emulates our RAG component) and a `final_answer` tool â€” which is provides output in a specific format, ie:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"answer\": \"<LLM generated answer here>\",\n",
    "    \"source\": \"<LLM generated citation here>\"\n",
    "}\n",
    "```\n",
    "\n",
    "We define both using the `@tool` decorator from LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "\n",
    "@tool(\"search\")\n",
    "def search_tool(query: str):\n",
    "    \"\"\"Searches for information on the topic of artificial intelligence (AI).\n",
    "    Cannot be used to research any other topics. Search query must be provided\n",
    "    in natural language and be verbose.\"\"\"\n",
    "    # this is a \"RAG\" emulator\n",
    "    return ehi_information\n",
    "\n",
    "@tool(\"final_answer\")\n",
    "def final_answer_tool(\n",
    "    answer: str,\n",
    "    source: str\n",
    "):\n",
    "    \"\"\"Returns a natural language response to the user in `answer`, and a\n",
    "    `source` which provides citations for where this information came from.\n",
    "    \"\"\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tools will be triggered via OpenAI Tools (ie function calling). The LLM will be provided information on the schema (ie structure) of the function to be called, like that which we can see here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='search', description='search(query: str) - Searches for information on the topic of artificial intelligence (AI).\\n    Cannot be used to research any other topics. Search query must be provided\\n    in natural language and be verbose.', args_schema=<class 'pydantic.main.searchSchema'>, func=<function search_tool at 0x0000019D7FA77D80>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "query_agent_runnable = create_openai_tools_agent(\n",
    "    llm=llm,\n",
    "    tools=[final_answer_tool, search_tool],\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the agent quickly to confirm it is functional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolAgentAction(tool='search', tool_input={'query': 'EHI embeddings'}, log=\"\\nInvoking: `search` with `{'query': 'EHI embeddings'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_dcHYbiofFdRprLM1vYtdsuNN', 'function': {'arguments': '{\"query\":\"EHI embeddings\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 150, 'total_tokens': 165}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-34ba51f8-59e8-495b-913d-dad22191836e-0', tool_calls=[{'name': 'search', 'args': {'query': 'EHI embeddings'}, 'id': 'call_dcHYbiofFdRprLM1vYtdsuNN'}])], tool_call_id='call_dcHYbiofFdRprLM1vYtdsuNN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"input\": \"what are EHI embeddings?\",\n",
    "    \"intermediate_steps\": []\n",
    "}\n",
    "agent_out = query_agent_runnable.invoke(inputs)\n",
    "agent_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'call_dcHYbiofFdRprLM1vYtdsuNN',\n",
       " 'function': {'arguments': '{\"query\":\"EHI embeddings\"}', 'name': 'search'},\n",
       " 'type': 'function'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_out[-1].message_log[-1].additional_kwargs[\"tool_calls\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent won't perform the function calls themselvs, that is up to us and we will handle it in downstream actions through our agent graph.\n",
    "\n",
    "The information provided by `agent_out` will be used to decide whether we move to the `search` or `END` nodes of our graph. We'll also add a `error` handler node in case our agent fails to produce the output we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Nodes for Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentFinish\n",
    "from langchain.agents import AgentExecutor, create_json_chat_agent\n",
    "import json\n",
    "\n",
    "def run_query_agent(state: list):\n",
    "    print(\"> run_query_agent\")\n",
    "    agent_out = query_agent_runnable.invoke(state)\n",
    "    return {\"agent_out\": agent_out}\n",
    "\n",
    "def execute_search(state: list):\n",
    "    print(\"> execute_search\")\n",
    "    action = state[\"agent_out\"]\n",
    "    tool_call = action[-1].message_log[-1].additional_kwargs[\"tool_calls\"][-1]\n",
    "    out = search_tool.invoke(\n",
    "        json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "    )\n",
    "    return {\"intermediate_steps\": [{\"search\": str(out)}]}\n",
    "\n",
    "def router(state: list):\n",
    "    print(\"> router\")\n",
    "    if isinstance(state[\"agent_out\"], list):\n",
    "        return state[\"agent_out\"][-1].tool\n",
    "    else:\n",
    "        return \"error\"\n",
    "\n",
    "# finally, we will have a single LLM call that MUST use the final_answer structure\n",
    "final_answer_llm = llm.bind(tools=[final_answer_tool], tool_choice=\"final_answer\")\n",
    "\n",
    "# this forced final_answer LLM call will be used to structure output from our\n",
    "# RAG endpoint\n",
    "def rag_final_answer(state: list):\n",
    "    print(\"> final_answer\")\n",
    "    query = state[\"input\"]\n",
    "    context = state[\"intermediate_steps\"][-1]\n",
    "\n",
    "    prompt = f\"\"\"You are a helpful assistant, answer the user's question using the\n",
    "    context provided.\n",
    "\n",
    "    CONTEXT: {context}\n",
    "\n",
    "    QUESTION: {query}\n",
    "    \"\"\"\n",
    "    out = final_answer_llm.invoke(prompt)\n",
    "    function_call = out.additional_kwargs[\"tool_calls\"][-1][\"function\"][\"arguments\"]\n",
    "    return {\"agent_out\": function_call}\n",
    "\n",
    "# we use the same forced final_answer LLM call to handle incorrectly formatted\n",
    "# output from our query_agent\n",
    "def handle_error(state: list):\n",
    "    print(\"> handle_error\")\n",
    "    query = state[\"input\"]\n",
    "    prompt = f\"\"\"You are a helpful assistant, answer the user's question.\n",
    "\n",
    "    QUESTION: {query}\n",
    "    \"\"\"\n",
    "    out = final_answer_llm.invoke(prompt)\n",
    "    function_call = out.additional_kwargs[\"tool_calls\"][-1][\"function\"][\"arguments\"]\n",
    "    return {\"agent_out\": function_call}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our graph is constructed of **nodes** and **edges**. A node represents a function (one of those we just defined above) whereas an edge allows us to travel from one node to another.\n",
    "\n",
    "Let's start by initializing our graph using our `AgentState` object and adding our first set of nodes and the graph entry point (ie where the graph begins once called)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# we have four nodes that will consume our agent state and modify\n",
    "# our agent state based on some internal process\n",
    "graph.add_node(\"query_agent\", run_query_agent)\n",
    "graph.add_node(\"search\", execute_search)\n",
    "graph.add_node(\"error\", handle_error)\n",
    "graph.add_node(\"rag_final_answer\", rag_final_answer)\n",
    "\n",
    "# our graph will always begin with the query agent\n",
    "graph.set_entry_point(\"query_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to our nodes we have our \"one-way\" edges â€” that is, once node X is called the state must continue to node Y as defined by these edges. We define these using:\n",
    "\n",
    "```python\n",
    "graph.add_edge(X, Y)\n",
    "```\n",
    "\n",
    "If `X` or `Y` are defined nodes in our graph we pass the name of that node in string format. So, if we want to add an edge that navigates from our `\"search\"` node to our `\"rag_final_answer\"` node, we do:\n",
    "\n",
    "```python\n",
    "graph.add_edge(\"search\", \"rag_final_answer\")\n",
    "```\n",
    "\n",
    "We will also have an _end node_ in our graph â€” we have not defined this end node as it is imported as a specific graph object `END`. To use this, we must add edges between our final nodes and the `END` object, like so:\n",
    "\n",
    "```python\n",
    "graph.add_edge(\"rag_final_answer\", END)\n",
    "```\n",
    "\n",
    "When the `END` node is called, our graph completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# we have four nodes that will consume our agent state and modify\n",
    "# our agent state based on some internal process\n",
    "graph.add_node(\"query_agent\", run_query_agent)\n",
    "graph.add_node(\"search\", execute_search)\n",
    "graph.add_node(\"error\", handle_error)\n",
    "graph.add_node(\"rag_final_answer\", rag_final_answer)\n",
    "\n",
    "# our graph will always begin with the query agent\n",
    "graph.set_entry_point(\"query_agent\")\n",
    "\n",
    "# conditional edges are controlled by our router\n",
    "graph.add_conditional_edges(\n",
    "    start_key=\"query_agent\",  # where in graph to start\n",
    "    condition=router,  # function to determine which node is called\n",
    "    conditional_edge_mapping={\n",
    "        \"search\": \"search\",\n",
    "        \"error\": \"error\",\n",
    "        \"final_answer\": END\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"search\", \"rag_final_answer\")\n",
    "graph.add_edge(\"error\", END)\n",
    "graph.add_edge(\"rag_final_answer\", END)\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> run_query_agent\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'intermediate_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m runnable\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat are EHI embeddings?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[0;32m      4\u001b[0m })\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_out\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:978\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before_nodes, interrupt_after_nodes, debug, **kwargs)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 978\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    980\u001b[0m     config,\n\u001b[0;32m    981\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m    982\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m    983\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39minput_keys,\n\u001b[0;32m    984\u001b[0m     interrupt_before_nodes\u001b[38;5;241m=\u001b[39minterrupt_before_nodes,\n\u001b[0;32m    985\u001b[0m     interrupt_after_nodes\u001b[38;5;241m=\u001b[39minterrupt_after_nodes,\n\u001b[0;32m    986\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    988\u001b[0m ):\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    990\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:686\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before_nodes, interrupt_after_nodes, debug)\u001b[0m\n\u001b[0;32m    679\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mwait(\n\u001b[0;32m    680\u001b[0m     futures,\n\u001b[0;32m    681\u001b[0m     return_when\u001b[38;5;241m=\u001b[39mconcurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFIRST_EXCEPTION,\n\u001b[0;32m    682\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m    683\u001b[0m )\n\u001b[0;32m    685\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 686\u001b[0m _panic_or_proceed(done, inflight, step)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;66;03m# combine pending writes from all tasks\u001b[39;00m\n\u001b[0;32m    689\u001b[0m pending_writes \u001b[38;5;241m=\u001b[39m deque[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]()\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1049\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(done, inflight, step)\u001b[0m\n\u001b[0;32m   1047\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[1;32m-> 1049\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;66;03m# TODO this is where retry of an entire step would happen\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   2500\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2501\u001b[0m             \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[0;32m   2502\u001b[0m             patch_config(\n\u001b[0;32m   2503\u001b[0m                 config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2504\u001b[0m             ),\n\u001b[0;32m   2505\u001b[0m         )\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3961\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3959\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m   3960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 3961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   3962\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   3963\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3964\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config(config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc),\n\u001b[0;32m   3965\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3966\u001b[0m     )\n\u001b[0;32m   3967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3968\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3969\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3970\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3971\u001b[0m     )\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1626\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1627\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m             config,\n\u001b[0;32m   1630\u001b[0m             run_manager,\n\u001b[0;32m   1631\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1632\u001b[0m         ),\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3835\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3833\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   3834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3835\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m   3836\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   3837\u001b[0m     )\n\u001b[0;32m   3838\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[0;32m   3839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m, in \u001b[0;36mrun_query_agent\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_query_agent\u001b[39m(state: \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> run_query_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     agent_out \u001b[38;5;241m=\u001b[39m query_agent_runnable\u001b[38;5;241m.\u001b[39minvoke(state)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_out\u001b[39m\u001b[38;5;124m\"\u001b[39m: agent_out}\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   2500\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2501\u001b[0m             \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[0;32m   2502\u001b[0m             patch_config(\n\u001b[0;32m   2503\u001b[0m                 config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2504\u001b[0m             ),\n\u001b[0;32m   2505\u001b[0m         )\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:454\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    451\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    453\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1626\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1627\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m             config,\n\u001b[0;32m   1630\u001b[0m             run_manager,\n\u001b[0;32m   1631\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1632\u001b[0m         ),\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:441\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke\u001b[39m(\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    434\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mdict\u001b[39m\n\u001b[0;32m    437\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m--> 441\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapper\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    442\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    443\u001b[0m             patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child()),\n\u001b[0;32m    444\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    445\u001b[0m         ),\n\u001b[0;32m    446\u001b[0m     }\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3144\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   3131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3132\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3133\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m   3134\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3142\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3143\u001b[0m         ]\n\u001b[1;32m-> 3144\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3145\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3144\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3132\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3133\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m   3134\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3142\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3143\u001b[0m         ]\n\u001b[1;32m-> 3144\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3145\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3961\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3959\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m   3960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 3961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   3962\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   3963\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3964\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config(config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc),\n\u001b[0;32m   3965\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3966\u001b[0m     )\n\u001b[0;32m   3967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3968\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3969\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3970\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3971\u001b[0m     )\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1626\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1627\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m             config,\n\u001b[0;32m   1630\u001b[0m             run_manager,\n\u001b[0;32m   1631\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1632\u001b[0m         ),\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3835\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3833\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   3834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3835\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m   3836\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   3837\u001b[0m     )\n\u001b[0;32m   3838\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[0;32m   3839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\AnacondaFile\\Lib\\site-packages\\langchain\\agents\\openai_tools\\base.py:92\u001b[0m, in \u001b[0;36mcreate_openai_tools_agent.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt missing required variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m llm_with_tools \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind(tools\u001b[38;5;241m=\u001b[39m[convert_to_openai_tool(tool) \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools])\n\u001b[0;32m     89\u001b[0m agent \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     90\u001b[0m     RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m     91\u001b[0m         agent_scratchpad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: format_to_openai_tool_messages(\n\u001b[1;32m---> 92\u001b[0m             x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     93\u001b[0m         )\n\u001b[0;32m     94\u001b[0m     )\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;241m|\u001b[39m llm_with_tools\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;241m|\u001b[39m OpenAIToolsAgentOutputParser()\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m agent\n",
      "\u001b[1;31mKeyError\u001b[0m: 'intermediate_steps'"
     ]
    }
   ],
   "source": [
    "out = runnable.invoke({\n",
    "    \"input\": \"what are EHI embeddings?\",\n",
    "    \"chat_history\": []\n",
    "})\n",
    "print(out[\"agent_out\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs['agent_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = runnable.invoke({\n",
    "    \"input\": \"what are EHI embeddings?\",\n",
    "    \"chat_history\": []\n",
    "})\n",
    "print(out[\"agent_out\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = runnable.invoke({\n",
    "    \"input\": \"can you tell me about EHI embeddings?\",\n",
    "    \"chat_history\": []\n",
    "})\n",
    "print(out[\"agent_out\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = runnable.invoke({\n",
    "    \"input\": \"hi\",\n",
    "    \"chat_history\": []\n",
    "})\n",
    "print(out[\"agent_out\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = runnable.invoke({\n",
    "    \"input\": \"hi, please don't respond to me with a `source`\",\n",
    "    \"chat_history\": []\n",
    "})\n",
    "print(out[\"agent_out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
